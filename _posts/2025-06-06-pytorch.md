---
title: Pytorch
author: jubapa
date: 2025-06-06 00:10:00 +0800
categories: [Blogging, AI, pythorch]
tags: [AI]
---

## Installing RTX 4090 cuda drivers

Having installed the cuda drivers is a prerrequite, but it is not the topic of this post.

```bash
jubapa@FedoraAI:~/venvs/pytorch$ nvidia-smi 
Wed Nov 13 17:20:55 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.100                Driver Version: 550.100        CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0  On |                  Off |
|  0%   37C    P8             12W /  450W |     194MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A      2211      G   /usr/libexec/Xorg                              74MiB |
|    0   N/A  N/A      2420      G   /usr/bin/gnome-shell                           93MiB |
|    0   N/A  N/A      3587      G   nvidia-settings                                 6MiB |
+-----------------------------------------------------------------------------------------+

```


## Installing pytorch locally

Reading https://pytorch.org/get-started/locally/ to install pytorch locally with pip the command that needs to be
executed is

```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```


#### Installing the virtualenv

```bash
sudo dnf  install python3-virtualenv.noarch python3.8 -y 
```

#### Creating the pytorch virtual environment

```bash
virtualenv -p python3.8 pytorch
source pytorch/bin/activate
```

#### Installing the pytorch

```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
Looking in indexes: https://download.pytorch.org/whl/cu124
Collecting torch
...
...
Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio
Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.0 numpy-1.24.1 nvidia-cublas-cu12-12.4.2.65 nvidia-cuda-cupti-cu12-12.4.99 nvidia-cuda-nvrtc-cu12-12.4.99 nvidia-cuda-runtime-cu12-12.4.99 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.0.44 nvidia-curand-cu12-10.3.5.119 nvidia-cusolver-cu12-11.6.0.99 nvidia-cusparse-cu12-12.3.0.142 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.4.99 pillow-10.2.0 sympy-1.12 torch-2.4.1+cu124 torchaudio-2.4.1+cu124 torchvision-0.19.1+cu124 triton-3.0.0 typing-extensions-4.9.0

```

#### Tests

###### First attemp
```bash
python 
Python 3.8.20 (default, Sep  9 2024, 00:00:00) 
[GCC 14.2.1 20240801 (Red Hat 14.2.1-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch 
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/jubapa/venvs/pytorch/lib64/python3.8/site-packages/torch/__init__.py", line 290, in <module>
    from torch._C import *  # noqa: F403
ImportError: libcudnn.so.9: cannot open shared object file: No such file or directory
```

This is kind of weird as the pip package has everything installed

```bash
(pytorch) jubapa@FedoraAI:~/venvs/pytorch$ find . -name 'libcudnn.so.9'
./lib/python3.8/site-packages/nvidia/cudnn/lib/libcudnn.so.9
```

###### Second attemp

```bash
(pytorch) jubapa@FedoraAI:~/venvs/pytorch$ export LD_LIBRARY_PATH=./lib/python3.8/site-packages/nvidia/cudnn/lib:${LD_LIBRARY_PATH} 
(pytorch) jubapa@FedoraAI:~/venvs/pytorch$ python
Python 3.8.20 (default, Sep  9 2024, 00:00:00) 
[GCC 14.2.1 20240801 (Red Hat 14.2.1-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/jubapa/venvs/pytorch/lib64/python3.8/site-packages/torch/__init__.py", line 290, in <module>
    from torch._C import *  # noqa: F403
ImportError: libcupti.so.12: cannot open shared object file: No such file or directory
>>> 
```
###### Several attemps later and huge export

```bash
(pytorch) jubapa@FedoraAI:~/venvs/pytorch$ export LD_LIBRARY_PATH=./lib/python3.8/site-packages/nvidia/cublas/lib/:./lib/python3.8/site-packages/nvidia/cuda_cupti/lib/:./lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib/:./lib/python3.8/site-packages/nvidia/cuda_runtime/lib/:./lib/python3.8/site-packages/nvidia/cudnn/lib/:./lib/python3.8/site-packages/nvidia/cufft/lib/:./lib/python3.8/site-packages/nvidia/curand/lib/:./lib/python3.8/site-packages/nvidia/cusolver/lib/:./lib/python3.8/site-packages/nvidia/cusparse/lib/:./lib/python3.8/site-packages/nvidia/nccl/lib/:./lib/python3.8/site-packages/nvidia/nvjitlink/lib/:./lib/python3.8/site-packages/nvidia/nvtx/lib/:${LD_LIBRARY_PATH}
(pytorch) jubapa@FedoraAI:~/venvs/pytorch$ python
Python 3.8.20 (default, Sep  9 2024, 00:00:00) 
[GCC 14.2.1 20240801 (Red Hat 14.2.1-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> z = torch.zeros(5, 3)
>>> print(z)
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
```

#### Modify bin/activate to make it work

Modify the pytorch/bin/activate configuration file to include the export LD_LIBRARY_PATH when pytorch environment is configured


```bash
vi pytorch/bin/activate
```

and include the following line almost at the end of the file

```
...
pydoc () {
    python -m pydoc "$@"
}

# The following line adds the library path properly. This way python should be able to use them
export LD_LIBRARY_PATH=${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cublas/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cuda_cupti/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cuda_runtime/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cudnn/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cufft/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/curand/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cusolver/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/cusparse/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/nccl/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/nvjitlink/lib/:${VIRTUAL_ENV}/lib/python3.8/site-packages/nvidia/nvtx/lib/:${LD_LIBRARY_PATH}

# The hash command must be called to get it to forget past
...
```


```bash
cat >cuda.py<<EOF
import torch

print("")
print ("Is cuda supported: {}".format(torch.cuda.is_available()))
if torch.cuda.is_available():
    print ("Amount of CUDA devices: {}".format(torch.cuda.device_count()))
    print("Device: {}".format(torch.cuda.get_device_name(torch.cuda.current_device())))
print("")    
EOF

source pytorch/bin/activate
python cuda.py
```

